{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383075d4f797ffc1",
   "metadata": {},
   "source": [
    "# Lab 4-1: Data preprocessing. Building a regression model.\n",
    "\n",
    "In this lab will write a simple regression model to predict the solubility of chemical molecules. We will use the `RDKit` library to calculate molecular descriptors from SMILES strings, and the `scikit-learn` library to build a regression model.\n",
    "\n",
    "We will learn how to get different molecular decriptors from SMILES strings with the use od `RDKit` library. Then we will preprocess data, implement a featurizer for automatic input data preparation, and wrap the whole process in a simple, user-friendly web app using `Streamlit`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a509e53faea6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n",
       "      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
       "      <td>-3.616127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>Clc1ccc(C=O)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>\n",
       "      <td>[Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...</td>\n",
       "      <td>-3.924409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
       "1                           Benzo[cd]indol-2(1H)-one   \n",
       "2                               4-chlorobenzaldehyde   \n",
       "3  zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...   \n",
       "4  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "\n",
       "                                              SMILES  Solubility  \n",
       "0                [Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C   -3.616127  \n",
       "1                               O=C1Nc2cccc3cccc1c23   -3.254767  \n",
       "2                                    Clc1ccc(C=O)cc1   -2.177078  \n",
       "3  [Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...   -3.924409  \n",
       "4  C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/aqsol.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab12a34250cf4e1",
   "metadata": {},
   "source": [
    "## Calculating molecular descriptors with RDKit\n",
    "\n",
    "**RDKit is a collection of cheminformatics tools, widely used to analyze and process chemical data.** We will use some of its functionalities to calculate molecular descriptors for the molecules in our dataset, and use the descriptors as input features for a regression model that will learn to predict the solubility of the molecules from SMILES strings. \n",
    "\n",
    "For this task will use only one submodule of RDKit, `rdkit.Chem.rdMolDescriptors`, which contains functions for calculating the molecular descriptors we are interested in. Feel free to explore RDKit yourself by reading [rdMolDescriptors documentation](https://www.rdkit.org/docs/source/rdkit.Chem.rdMolDescriptors.html) and [RDKit documentation](https://www.rdkit.org/docs/index.html).\n",
    "\n",
    "The most important RDKit class is `Mol` which represents a molecule with its atoms, bonds, spatial conformation, etc. Most RDKit functions, including those for calculating molecular descriptors, take a `Mol` object as input. If you have a SMILES string, you can create a `Mol` object using the `Chem.MolFromSmiles` function, as shown below:\n",
    "\n",
    "```python\n",
    "from rdkit import Chem\n",
    "\n",
    "smiles = 'C1C(=O)NC2=C(C=C(C=C2)[N+](=O)[O-])C(=N1)C3=CC=CC=C3'\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d60f4277dd88387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>mol</th>\n",
       "      <th>mol_wt</th>\n",
       "      <th>logp</th>\n",
       "      <th>num_heavy_atoms</th>\n",
       "      <th>num_HBD</th>\n",
       "      <th>num_HBA</th>\n",
       "      <th>aromatic_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n",
       "      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
       "      <td>-3.616127</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000018088F...</td>\n",
       "      <td>391.281363</td>\n",
       "      <td>3.9581</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000018088F...</td>\n",
       "      <td>169.052764</td>\n",
       "      <td>2.4055</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>Clc1ccc(C=O)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000018088F...</td>\n",
       "      <td>140.002892</td>\n",
       "      <td>2.1525</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>\n",
       "      <td>[Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...</td>\n",
       "      <td>-3.924409</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000018088F...</td>\n",
       "      <td>754.227281</td>\n",
       "      <td>8.1161</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x0000018088F...</td>\n",
       "      <td>422.220557</td>\n",
       "      <td>2.4854</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
       "1                           Benzo[cd]indol-2(1H)-one   \n",
       "2                               4-chlorobenzaldehyde   \n",
       "3  zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...   \n",
       "4  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "\n",
       "                                              SMILES  Solubility  \\\n",
       "0                [Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C   -3.616127   \n",
       "1                               O=C1Nc2cccc3cccc1c23   -3.254767   \n",
       "2                                    Clc1ccc(C=O)cc1   -2.177078   \n",
       "3  [Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...   -3.924409   \n",
       "4  C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065   \n",
       "\n",
       "                                                 mol      mol_wt    logp  \\\n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x0000018088F...  391.281363  3.9581   \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x0000018088F...  169.052764  2.4055   \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x0000018088F...  140.002892  2.1525   \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x0000018088F...  754.227281  8.1161   \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x0000018088F...  422.220557  2.4854   \n",
       "\n",
       "   num_heavy_atoms  num_HBD  num_HBA  aromatic_rings  \n",
       "0               23        0        0               0  \n",
       "1               13        1        1               2  \n",
       "2                9        0        1               1  \n",
       "3               53        2        6               6  \n",
       "4               31        0        6               2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import Crippen\n",
    "from rdkit import RDLogger  \n",
    "RDLogger.DisableLog('rdApp.*') # Disabling rdkit warnings\n",
    "\n",
    "# First, we will create a mol object for each molecule in the dataset, and store it in a new column\n",
    "df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "# Now we can calculate the molecular descriptors\n",
    "df['mol_wt'] = df['mol'].apply(rdMolDescriptors.CalcExactMolWt)             # Molecular weight\n",
    "df['logp'] = df['mol'].apply(Crippen.MolLogP)      # LogP (lipophilicity)\n",
    "df['num_heavy_atoms'] = df['mol'].apply(rdMolDescriptors.CalcNumHeavyAtoms) # Number of heavy atoms\n",
    "df['num_HBD'] = df['mol'].apply(rdMolDescriptors.CalcNumHBD)                # Number of hydrogen bond donors\n",
    "df['num_HBA'] = df['mol'].apply(rdMolDescriptors.CalcNumHBA)                # Number of hydrogen bond acceptors\n",
    "df['aromatic_rings'] = df['mol'].apply(rdMolDescriptors.CalcNumAromaticRings) # Number of aromatic rings\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b96d1421ed6e46",
   "metadata": {},
   "source": [
    "## Exercise 1: Extract features and split the dataset (1 point)\n",
    "\n",
    "Now that we have the molecular descriptors, we can use them as input features for a regression model. As we did in the previous lab, we will extract the **input features** $X$ and the target variable $y$, and split the dataset into training and test sets.\n",
    "\n",
    "Let's use the newly calculated molecular descriptors as input features, and the solubility as the target variable.\n",
    "\n",
    "1. Extract the input features and the target variable from the dataset\n",
    "2. Split the dataset into training and test sets, with a test size of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf2da0c4db1756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the relevant columns of the dataframe (features and target)\n",
    "\n",
    "y = df['Solubility']\n",
    "X = df[['SMILES', 'mol_wt', 'num_heavy_atoms', 'num_HBD', 'num_HBA', 'aromatic_rings', 'logp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc72dac8094e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train_nosmiles = X_train.drop(columns = ['SMILES'])\n",
    "X_test_nosmiles = X_test.drop(columns = ['SMILES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e695e991ef6e8",
   "metadata": {},
   "source": [
    "## Exercise 2: Build a regression model (2 points)\n",
    "\n",
    "You already know the `scikit-learn` library, as we used it to build some classifier models in the previous labs. Now, we will use it to build a regression model. Linear regression is the simplest regression model, and it is a good starting point for regression problems. It is implemented in scikit-learn as `LinearRegression`. You should also try a more complex model, such as `SVR` (Support Vector Regression) and compare the results.\n",
    "\n",
    "1. Train a `LinearRegression` model on the training set. Report $RMSE$ (Root Mean Squared Error) and $R^2$ score on the train and test sets.\n",
    "2. Train an `SVR` model on the training set. Report $RMSE$ and $R^2$ score on the train and test sets. **Use the default hyperparameters for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd091b6b7bf3023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for LR: 1.726312060290738\n",
      "Training R^2 for LR: 2.980153329505253\n",
      "Testing RMSE for LR: 1.8064467610979604\n",
      "Testing R^2 for LR: 3.2632499006813114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math \n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_nosmiles, y_train)\n",
    "\n",
    "train_pred_lr = lr.predict(X_train_nosmiles)  # make predictions on the training set\n",
    "test_pred_lr = lr.predict(X_test_nosmiles)  # make predictions on the testing set\n",
    "\n",
    "R_2_lr_train = mean_squared_error(y_train, train_pred_lr)\n",
    "RMSE_lr_train = math.sqrt(R_2_lr_train)\n",
    "print('Training RMSE for LR:', RMSE_lr_train)\n",
    "print('Training R^2 for LR:', R_2_lr_train)\n",
    "\n",
    "R_2_lr_test = mean_squared_error(y_test, test_pred_lr)\n",
    "RMSE_lr_test = math.sqrt(R_2_lr_test)\n",
    "print('Testing RMSE for LR:', RMSE_lr_test)\n",
    "print('Testing R^2 for LR:', R_2_lr_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74bdd13-1789-47ca-b267-50bce766d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for SVR: 1.721510403937339\n",
      "Training R^2 for SVR: 2.9635980708645\n",
      "Testing RMSE for SVR: 1.7391769387441625\n",
      "Testing R^2 for SVR: 3.0247364242595163\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train_nosmiles, y_train)\n",
    "\n",
    "train_pred_svr = svr.predict(X_train_nosmiles)  # make predictions on the training set\n",
    "test_pred_svr = svr.predict(X_test_nosmiles)  # make predictions on the testing set\n",
    "\n",
    "R_2_svr_train = mean_squared_error(y_train, train_pred_svr)\n",
    "RMSE_svr_train = math.sqrt(R_2_svr_train)\n",
    "print('Training RMSE for SVR:', RMSE_svr_train)\n",
    "print('Training R^2 for SVR:', R_2_svr_train)\n",
    "\n",
    "R_2_svr_test = mean_squared_error(y_test, test_pred_svr)\n",
    "RMSE_svr_test = math.sqrt(R_2_svr_test)\n",
    "print('Testing RMSE for SVR:', RMSE_svr_test)\n",
    "print('Testing R^2 for SVR:', R_2_svr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba17e8dbfa3cfdc",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "**Standardization** of datasets is a common requirement for many machine learning estimators implemented in scikit-learn. If some features of our data have very different scales (for example, one feature is in the range $[0, 1]$ and another can potentially be any positive number), **some models** might consider the feature with larger numerical values to be more important. This can be a problem, as we want our model to be able to learn from all features equally.\n",
    "\n",
    "Standardization transform our data in such a way that its distribution will have a mean value $\\mu = 0$ and standard deviation $\\sigma = 1$. We can achieve this by using the `StandardScaler` from the `sklearn` library.\n",
    "\n",
    "Another common preprocessing step is **normalization**. In this case, the data is scaled to a fixed range, usually $[0, 1]$. The motivation to use this scaling method includes preserving zeros in sparse data. For example, when making predictions about the expected outcome of an anticancer therapy, the value of $0$ observed tumors in a patient is probably much more informative for the predictive model than any other number of observed tumors alone. We can scale data to a certain range by using the `MinMaxScaler` from the `sklearn` library.\n",
    "\n",
    "You can read more about those two feature scaling methods in the [Scikit-learn preprocessing docs](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "\n",
    "<center>\n",
    "    <img src=\"imgs/logp-std.png\" width=\"500\">\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Remember that the scaler should be fitted only on the training set, and then used to transform both the training and test sets.** If we first transform the entire dataset and then split it into training and test sets, we are leaking the information about **test set data distribution** to the model, which would lead to overly optimistic results.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "## Exercise 3: Preprocess the input features (2 points)\n",
    "\n",
    "1. Standardize the input features using the `StandardScaler` from `sklearn`. **Fit the scaler on the training set and then transform both the training and test sets**.\n",
    "2. Train both linear regression and SVR models on the standardized training set. Report $RMSE$ and $R^2$ score on the train and test sets. How do the results compare to the previous models? Which model benefits from standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b760550de9e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_st = scaler.fit_transform(X_train_nosmiles)\n",
    "X_test_st = scaler.transform(X_test_nosmiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657e0cc9-207a-4f6f-a710-7248e75c4ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(X_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db52bcb1-a7d0-4754-9093-be9e8ca291eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for LR: 1.7263120602907382\n",
      "Training R^2 for LR: 2.9801533295052534 \n",
      "\n",
      "Testing RMSE for LR: 1.806446761097952\n",
      "Testing R^2 for LR: 3.2632499006812816\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_st, y_train)\n",
    "\n",
    "train_pred_lr_st = lr.predict(X_train_st)  # make predictions on the standardized training set\n",
    "test_pred_lr_st = lr.predict(X_test_st)  # make predictions on the standardized testing set\n",
    "\n",
    "R_2_lr_train_st = mean_squared_error(y_train, train_pred_lr_st)\n",
    "RMSE_lr_train_st = math.sqrt(R_2_lr_train_st)\n",
    "print('Training RMSE for LR:', RMSE_lr_train_st)\n",
    "print('Training R^2 for LR:', R_2_lr_train_st, '\\n')\n",
    "\n",
    "R_2_lr_test_st = mean_squared_error(y_test, test_pred_lr_st)\n",
    "RMSE_lr_test_st = math.sqrt(R_2_lr_test_st)\n",
    "print('Testing RMSE for LR:', RMSE_lr_test_st)\n",
    "print('Testing R^2 for LR:', R_2_lr_test_st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942305f4-c0fb-4bb3-a7d5-8568691baf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for SVR: 1.2946324501090385\n",
      "Training R^2 for SVR: 1.676073180875332 \n",
      "\n",
      "Testing RMSE for SVR: 1.3049162737852684\n",
      "Testing R^2 for SVR: 1.7028064815896298\n"
     ]
    }
   ],
   "source": [
    "svr.fit(X_train_st, y_train)\n",
    "\n",
    "train_pred_svr_st = svr.predict(X_train_st)  # make predictions on the standardized training set\n",
    "test_pred_svr_st = svr.predict(X_test_st)  # make predictions on the standardized testing set\n",
    "\n",
    "RMSE_svr_train_st = math.sqrt(mean_squared_error(y_train, train_pred_svr_st))\n",
    "R_2_svr_train_st = mean_squared_error(y_train, train_pred_svr_st)\n",
    "print('Training RMSE for SVR:', RMSE_svr_train_st)\n",
    "print('Training R^2 for SVR:', R_2_svr_train_st, '\\n')\n",
    "\n",
    "RMSE_svr_test_st = math.sqrt(mean_squared_error(y_test, test_pred_svr_st))\n",
    "R_2_svr_test_st = mean_squared_error(y_test, test_pred_svr_st)\n",
    "print('Testing RMSE for SVR:', RMSE_svr_test_st)\n",
    "print('Testing R^2 for SVR:', R_2_svr_test_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7788a1513ee0f54",
   "metadata": {},
   "source": [
    "## *Exercise: Featurizer class\n",
    "\n",
    "All the data manipulations, including the generation of features (molecular descriptors) and scaling we did completely by hand. Imagine that we have a new dataset with molecules for which we want to predict the solubility. We would have to repeat all the steps we did above, which is not at all user-friendly.\n",
    "\n",
    "Let's encapsulate all the steps in a single class called `Featurizer`. \n",
    "\n",
    "**Featurizer is a piece of code which takes care of extracting the features and preparing them** in such a way that they can be used as an input for a ML model. In this fashion, our featurizer will be able to take a list of SMILES strings and return a dataframe with the molecular descriptors, ready to be used in any regression model.\n",
    "\n",
    "The `Featurizer` class should have the following methods:\n",
    "\n",
    "1. `__init__(self, smiles)`\n",
    "\n",
    "    The constructor method should take an array of **training set** SMILES strings as input and calculate the molecular descriptors for each molecule (in a `pandas.DataFrame`, as we did earlier). **It should also fit a scaler to the descriptors.** The descriptors should be stored in a dataframe, and the scaler should be stored as an attribute of the class.\n",
    "      \n",
    "\n",
    "2. `featurize(self, smiles)`\n",
    "    \n",
    "   This method should take an array of SMILES strings as input and return a dataframe with the molecular descriptors calculated with RDKit. **The descriptors should be standardized using the scaler which was fitted to the training set in the `__init__` method**.\n",
    "\n",
    "3. **You are more than welcome to implement other methods** if you think it will make your code cleaner or more efficient. Maybe we could have a separate method for the calculation of molecular descriptors, or for the scaling of the features?\n",
    "\n",
    "\n",
    "### Here is an example of how our `Featurizer` class should be used\n",
    "```python\n",
    "featurizer = Featurizer(X_train['SMILES'])  # Create an instance of the Featurizer class, passing the training set SMILES strings\n",
    "\n",
    "# Say we want to predict the solubility of the following molecules\n",
    "some_SMILES = ['CC(=O)Oc1ccccc1C(=O)O',     \n",
    "               'C1=CC(=C(C=C1[C@H](CN)O)O)O',\n",
    "               'C1=NC2=C(C(=N1)N)N=CN2C3C(C(C(O3)CO)O)O']\n",
    "\n",
    "# Extract the features\n",
    "X = featurizer.featurize(some_SMILES)\n",
    "\n",
    "...\n",
    "\n",
    "y_pred = model.predict(X)   # Get predictions\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdba06d2dc54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featurizer:\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, train_smiles):\n",
    "        self.scaler = StandardScaler()\n",
    "        train_descriptors = self.get_descriptors(train_smiles)\n",
    "        self.scaler.fit(train_descriptors)\n",
    "\n",
    "    def featurize(self, smiles):\n",
    "        descriptors = self.get_descriptors(smiles)\n",
    "        scaled_descriptors = self.scaler.transform(descriptors)\n",
    "        return scaled_descriptors\n",
    "\n",
    "    def get_descriptors(self, smiles):\n",
    "        df = pd.DataFrame({'SMILES':smiles})\n",
    "        df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "        df['mol_wt'] = df['mol'].apply(rdMolDescriptors.CalcExactMolWt)             # Molecular weight\n",
    "        df['logp'] = df['mol'].apply(Crippen.MolLogP)                               # LogP (lipophilicity)\n",
    "        df['num_heavy_atoms'] = df['mol'].apply(rdMolDescriptors.CalcNumHeavyAtoms) # Number of heavy atoms\n",
    "        df['num_HBD'] = df['mol'].apply(rdMolDescriptors.CalcNumHBD)                # Number of hydrogen bond donors\n",
    "        df['num_HBA'] = df['mol'].apply(rdMolDescriptors.CalcNumHBA)                # Number of hydrogen bond acceptors\n",
    "        df['aromatic_rings'] = df['mol'].apply(rdMolDescriptors.CalcNumAromaticRings) # Number of aromatic rings\n",
    "        return  df[['mol_wt', 'num_heavy_atoms', 'num_HBD', 'num_HBA', 'aromatic_rings', 'logp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8054c47c9dab6f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1=CC=C2C(=C1)C(=CN2)CCN</td>\n",
       "      <td>Tryptamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNS(=O)(=O)CC1=CC2=C(NC=C2CCN(C)C)C=C1</td>\n",
       "      <td>Sumatriptan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)N(CCC1=CNC2=CC=CC=C21)C(C)C</td>\n",
       "      <td>DiPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)NCCC1=CNC2=C1C=C(C=C2)OC</td>\n",
       "      <td>Melatonin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC(C)CC1=CNC2=C1C=CC=C2</td>\n",
       "      <td>AMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SMILES         Name\n",
       "0                C1=CC=C2C(=C1)C(=CN2)CCN   Tryptamine\n",
       "1  CNS(=O)(=O)CC1=CC2=C(NC=C2CCN(C)C)C=C1  Sumatriptan\n",
       "2        CC(C)N(CCC1=CNC2=CC=CC=C21)C(C)C         DiPT\n",
       "3          CC(=O)NCCC1=CNC2=C1C=C(C=C2)OC    Melatonin\n",
       "4                 NC(C)CC1=CNC2=C1C=CC=C2          AMT"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your featurizer\n",
    "\n",
    "featurizer = Featurizer(X_train['SMILES']) # Pass the training set SMILES strings to the constructor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tryptamines = pd.read_csv('data/tryptamines.csv')   # Load a new dataset\n",
    "tryptamines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb8e9765cba0f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59471675, -0.45790249,  0.58001366, -0.72713196,  0.73571964,\n",
       "        -0.08677079],\n",
       "       [ 0.15888908,  0.21985219,  0.58001366, -0.14600868,  0.73571964,\n",
       "        -0.1865212 ],\n",
       "       [-0.12540534,  0.05041352, -0.07646905, -0.72713196,  0.73571964,\n",
       "         0.53257632],\n",
       "       [-0.19278108, -0.03430581,  0.58001366, -0.43657032,  0.73571964,\n",
       "        -0.03344059],\n",
       "       [-0.51649818, -0.37318315,  0.58001366, -0.72713196,  0.73571964,\n",
       "         0.02462051],\n",
       "       [-0.5054523 , -0.37318315,  1.23649637, -0.43657032,  0.73571964,\n",
       "        -0.1711816 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = featurizer.featurize(tryptamines['SMILES'])   # Extract features for the new dataset\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c47cf735cf5cb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Name</th>\n",
       "      <th>Solubility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1=CC=C2C(=C1)C(=CN2)CCN</td>\n",
       "      <td>Tryptamine</td>\n",
       "      <td>-2.718853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNS(=O)(=O)CC1=CC2=C(NC=C2CCN(C)C)C=C1</td>\n",
       "      <td>Sumatriptan</td>\n",
       "      <td>-2.954978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)N(CCC1=CNC2=CC=CC=C21)C(C)C</td>\n",
       "      <td>DiPT</td>\n",
       "      <td>-3.798078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)NCCC1=CNC2=C1C=C(C=C2)OC</td>\n",
       "      <td>Melatonin</td>\n",
       "      <td>-2.921800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC(C)CC1=CNC2=C1C=CC=C2</td>\n",
       "      <td>AMT</td>\n",
       "      <td>-2.881083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SMILES         Name  Solubility\n",
       "0                C1=CC=C2C(=C1)C(=CN2)CCN   Tryptamine   -2.718853\n",
       "1  CNS(=O)(=O)CC1=CC2=C(NC=C2CCN(C)C)C=C1  Sumatriptan   -2.954978\n",
       "2        CC(C)N(CCC1=CNC2=CC=CC=C21)C(C)C         DiPT   -3.798078\n",
       "3          CC(=O)NCCC1=CNC2=C1C=C(C=C2)OC    Melatonin   -2.921800\n",
       "4                 NC(C)CC1=CNC2=C1C=CC=C2          AMT   -2.881083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the solubility of the new molecules\n",
    "\n",
    "y_pred = lr.predict(X)  # Use the linear regression model to predict the solubility\n",
    "\n",
    "tryptamines['Solubility'] = y_pred  # Add the predictions to the dataframe\n",
    "tryptamines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f535942fbf64684",
   "metadata": {},
   "source": [
    "## Cross-validation and grid search\n",
    "\n",
    "Now that we have a working regression model, we can try to improve its performance by tuning the hyperparameters. Last time we tuned the hyperparameters by hand, but as you may guess, that is not the most efficient way to do it. What we can (and will) do is employ a **search algorithm** to find the best hyperparameters automatically. This piece of code will try different hyperparameters and return the best combination.\n",
    "\n",
    "Last time we introduced the concept of a **validation set**, which is a subset of the training set used to evaluate the model's performance during hyperparameter tuning. To tune the hyperparameters of a classifier model we cut out a part of the training set and used the accuracy on this validation set as a metric to evaluate the model's performance.\n",
    "\n",
    "In practice, when tuning hyperparameters of a machine learning model, we do not usually create a single validation set. Instead, we employ a srategy called **cross-validation**. In $k$-fold cross-validation, the process of training and evaluating the model is repeated $k$ times, with each repetition using a different validation set. Thanks to this strategy, each data point present in the original training set will have the chance to be included in a validation sets. The metrics reported from $k$ folds are then averaged to get a more reliable estimate of the model's performance.\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/cross-validation.png\" width=\"800\">\n",
    "</center>\n",
    "\n",
    "Luckily, we do not have to implement this algorithm ourselves, as scikit-learn provides a `GridSearchCV` class that can help us with this task. It performs an exhaustive search over a specified parameter grid and evaluates the model's performance using $k$-fold cross-validation. By default, `GridSearchCV` uses a 5-fold cross-validation, which is a common choice for $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90aeecb460602ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END .................................C=1, epsilon=0.001; total time=   4.9s\n",
      "[CV] END .................................C=1, epsilon=0.001; total time=   5.4s\n",
      "[CV] END .................................C=1, epsilon=0.001; total time=   5.0s\n",
      "[CV] END .................................C=1, epsilon=0.001; total time=   5.1s\n",
      "[CV] END .................................C=1, epsilon=0.001; total time=   5.7s\n",
      "[CV] END ..................................C=1, epsilon=0.01; total time=   5.0s\n",
      "[CV] END ..................................C=1, epsilon=0.01; total time=   5.1s\n",
      "[CV] END ..................................C=1, epsilon=0.01; total time=   5.2s\n",
      "[CV] END ..................................C=1, epsilon=0.01; total time=   5.0s\n",
      "[CV] END ..................................C=1, epsilon=0.01; total time=   4.8s\n",
      "[CV] END ...................................C=1, epsilon=0.1; total time=   4.9s\n",
      "[CV] END ...................................C=1, epsilon=0.1; total time=   4.4s\n",
      "[CV] END ...................................C=1, epsilon=0.1; total time=   4.6s\n",
      "[CV] END ...................................C=1, epsilon=0.1; total time=   4.8s\n",
      "[CV] END ...................................C=1, epsilon=0.1; total time=   4.6s\n",
      "[CV] END ...................................C=1, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ...................................C=1, epsilon=0.5; total time=   3.6s\n",
      "[CV] END ...................................C=1, epsilon=0.5; total time=   3.6s\n",
      "[CV] END ...................................C=1, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ...................................C=1, epsilon=0.5; total time=   3.5s\n",
      "[CV] END .....................................C=1, epsilon=1; total time=   2.5s\n",
      "[CV] END .....................................C=1, epsilon=1; total time=   2.3s\n",
      "[CV] END .....................................C=1, epsilon=1; total time=   2.4s\n",
      "[CV] END .....................................C=1, epsilon=1; total time=   3.0s\n",
      "[CV] END .....................................C=1, epsilon=1; total time=   3.3s\n",
      "[CV] END .................................C=5, epsilon=0.001; total time=   4.8s\n",
      "[CV] END .................................C=5, epsilon=0.001; total time=   4.6s\n",
      "[CV] END .................................C=5, epsilon=0.001; total time=   4.5s\n",
      "[CV] END .................................C=5, epsilon=0.001; total time=   4.8s\n",
      "[CV] END .................................C=5, epsilon=0.001; total time=   5.4s\n",
      "[CV] END ..................................C=5, epsilon=0.01; total time=   5.2s\n",
      "[CV] END ..................................C=5, epsilon=0.01; total time=   6.3s\n",
      "[CV] END ..................................C=5, epsilon=0.01; total time=   4.9s\n",
      "[CV] END ..................................C=5, epsilon=0.01; total time=   4.7s\n",
      "[CV] END ..................................C=5, epsilon=0.01; total time=   4.6s\n",
      "[CV] END ...................................C=5, epsilon=0.1; total time=   4.3s\n",
      "[CV] END ...................................C=5, epsilon=0.1; total time=   4.3s\n",
      "[CV] END ...................................C=5, epsilon=0.1; total time=   4.3s\n",
      "[CV] END ...................................C=5, epsilon=0.1; total time=   4.3s\n",
      "[CV] END ...................................C=5, epsilon=0.1; total time=   4.3s\n",
      "[CV] END ...................................C=5, epsilon=0.5; total time=   3.2s\n",
      "[CV] END ...................................C=5, epsilon=0.5; total time=   3.2s\n",
      "[CV] END ...................................C=5, epsilon=0.5; total time=   3.2s\n",
      "[CV] END ...................................C=5, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ...................................C=5, epsilon=0.5; total time=   3.3s\n",
      "[CV] END .....................................C=5, epsilon=1; total time=   2.1s\n",
      "[CV] END .....................................C=5, epsilon=1; total time=   2.1s\n",
      "[CV] END .....................................C=5, epsilon=1; total time=   2.1s\n",
      "[CV] END .....................................C=5, epsilon=1; total time=   2.3s\n",
      "[CV] END .....................................C=5, epsilon=1; total time=   2.1s\n",
      "[CV] END ................................C=10, epsilon=0.001; total time=   5.3s\n",
      "[CV] END ................................C=10, epsilon=0.001; total time=   5.7s\n",
      "[CV] END ................................C=10, epsilon=0.001; total time=   5.8s\n",
      "[CV] END ................................C=10, epsilon=0.001; total time=   4.7s\n",
      "[CV] END ................................C=10, epsilon=0.001; total time=   5.0s\n",
      "[CV] END .................................C=10, epsilon=0.01; total time=   5.0s\n",
      "[CV] END .................................C=10, epsilon=0.01; total time=   5.5s\n",
      "[CV] END .................................C=10, epsilon=0.01; total time=   5.8s\n",
      "[CV] END .................................C=10, epsilon=0.01; total time=   5.3s\n",
      "[CV] END .................................C=10, epsilon=0.01; total time=   4.8s\n",
      "[CV] END ..................................C=10, epsilon=0.1; total time=   5.4s\n",
      "[CV] END ..................................C=10, epsilon=0.1; total time=   4.6s\n",
      "[CV] END ..................................C=10, epsilon=0.1; total time=   4.7s\n",
      "[CV] END ..................................C=10, epsilon=0.1; total time=   4.6s\n",
      "[CV] END ..................................C=10, epsilon=0.1; total time=   4.6s\n",
      "[CV] END ..................................C=10, epsilon=0.5; total time=   3.4s\n",
      "[CV] END ..................................C=10, epsilon=0.5; total time=   3.1s\n",
      "[CV] END ..................................C=10, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ..................................C=10, epsilon=0.5; total time=   3.4s\n",
      "[CV] END ..................................C=10, epsilon=0.5; total time=   3.4s\n",
      "[CV] END ....................................C=10, epsilon=1; total time=   2.2s\n",
      "[CV] END ....................................C=10, epsilon=1; total time=   2.1s\n",
      "[CV] END ....................................C=10, epsilon=1; total time=   2.1s\n",
      "[CV] END ....................................C=10, epsilon=1; total time=   2.1s\n",
      "[CV] END ....................................C=10, epsilon=1; total time=   2.2s\n",
      "[CV] END ................................C=20, epsilon=0.001; total time=   5.0s\n",
      "[CV] END ................................C=20, epsilon=0.001; total time=   5.0s\n",
      "[CV] END ................................C=20, epsilon=0.001; total time=   4.9s\n",
      "[CV] END ................................C=20, epsilon=0.001; total time=   5.0s\n",
      "[CV] END ................................C=20, epsilon=0.001; total time=   4.9s\n",
      "[CV] END .................................C=20, epsilon=0.01; total time=   4.8s\n",
      "[CV] END .................................C=20, epsilon=0.01; total time=   5.0s\n",
      "[CV] END .................................C=20, epsilon=0.01; total time=   4.9s\n",
      "[CV] END .................................C=20, epsilon=0.01; total time=   4.8s\n",
      "[CV] END .................................C=20, epsilon=0.01; total time=   4.9s\n",
      "[CV] END ..................................C=20, epsilon=0.1; total time=   4.8s\n",
      "[CV] END ..................................C=20, epsilon=0.1; total time=   4.6s\n",
      "[CV] END ..................................C=20, epsilon=0.1; total time=   5.1s\n",
      "[CV] END ..................................C=20, epsilon=0.1; total time=   4.5s\n",
      "[CV] END ..................................C=20, epsilon=0.1; total time=   4.9s\n",
      "[CV] END ..................................C=20, epsilon=0.5; total time=   3.1s\n",
      "[CV] END ..................................C=20, epsilon=0.5; total time=   3.1s\n",
      "[CV] END ..................................C=20, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ..................................C=20, epsilon=0.5; total time=   3.2s\n",
      "[CV] END ..................................C=20, epsilon=0.5; total time=   3.2s\n",
      "[CV] END ....................................C=20, epsilon=1; total time=   1.9s\n",
      "[CV] END ....................................C=20, epsilon=1; total time=   2.0s\n",
      "[CV] END ....................................C=20, epsilon=1; total time=   2.2s\n",
      "[CV] END ....................................C=20, epsilon=1; total time=   1.9s\n",
      "[CV] END ....................................C=20, epsilon=1; total time=   2.0s\n",
      "[CV] END ................................C=50, epsilon=0.001; total time=   5.2s\n",
      "[CV] END ................................C=50, epsilon=0.001; total time=   5.0s\n",
      "[CV] END ................................C=50, epsilon=0.001; total time=   5.4s\n",
      "[CV] END ................................C=50, epsilon=0.001; total time=   5.2s\n",
      "[CV] END ................................C=50, epsilon=0.001; total time=   5.2s\n",
      "[CV] END .................................C=50, epsilon=0.01; total time=   5.0s\n",
      "[CV] END .................................C=50, epsilon=0.01; total time=   5.2s\n",
      "[CV] END .................................C=50, epsilon=0.01; total time=   5.1s\n",
      "[CV] END .................................C=50, epsilon=0.01; total time=   5.2s\n",
      "[CV] END .................................C=50, epsilon=0.01; total time=   5.3s\n",
      "[CV] END ..................................C=50, epsilon=0.1; total time=   4.7s\n",
      "[CV] END ..................................C=50, epsilon=0.1; total time=   4.9s\n",
      "[CV] END ..................................C=50, epsilon=0.1; total time=   4.8s\n",
      "[CV] END ..................................C=50, epsilon=0.1; total time=   4.9s\n",
      "[CV] END ..................................C=50, epsilon=0.1; total time=   4.8s\n",
      "[CV] END ..................................C=50, epsilon=0.5; total time=   3.4s\n",
      "[CV] END ..................................C=50, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ..................................C=50, epsilon=0.5; total time=   3.3s\n",
      "[CV] END ..................................C=50, epsilon=0.5; total time=   3.5s\n",
      "[CV] END ..................................C=50, epsilon=0.5; total time=   3.3s\n",
      "[CV] END ....................................C=50, epsilon=1; total time=   2.0s\n",
      "[CV] END ....................................C=50, epsilon=1; total time=   2.1s\n",
      "[CV] END ....................................C=50, epsilon=1; total time=   2.1s\n",
      "[CV] END ....................................C=50, epsilon=1; total time=   2.1s\n",
      "[CV] END ....................................C=50, epsilon=1; total time=   2.0s\n",
      "[CV] END ...............................C=100, epsilon=0.001; total time=   5.3s\n",
      "[CV] END ...............................C=100, epsilon=0.001; total time=   5.2s\n",
      "[CV] END ...............................C=100, epsilon=0.001; total time=   5.4s\n",
      "[CV] END ...............................C=100, epsilon=0.001; total time=   5.7s\n",
      "[CV] END ...............................C=100, epsilon=0.001; total time=   5.2s\n",
      "[CV] END ................................C=100, epsilon=0.01; total time=   5.4s\n",
      "[CV] END ................................C=100, epsilon=0.01; total time=   5.6s\n",
      "[CV] END ................................C=100, epsilon=0.01; total time=   5.5s\n",
      "[CV] END ................................C=100, epsilon=0.01; total time=   5.4s\n",
      "[CV] END ................................C=100, epsilon=0.01; total time=   5.2s\n",
      "[CV] END .................................C=100, epsilon=0.1; total time=   4.9s\n",
      "[CV] END .................................C=100, epsilon=0.1; total time=   5.0s\n",
      "[CV] END .................................C=100, epsilon=0.1; total time=   5.1s\n",
      "[CV] END .................................C=100, epsilon=0.1; total time=   5.1s\n",
      "[CV] END .................................C=100, epsilon=0.1; total time=   5.1s\n",
      "[CV] END .................................C=100, epsilon=0.5; total time=   3.6s\n",
      "[CV] END .................................C=100, epsilon=0.5; total time=   3.3s\n",
      "[CV] END .................................C=100, epsilon=0.5; total time=   3.5s\n",
      "[CV] END .................................C=100, epsilon=0.5; total time=   3.4s\n",
      "[CV] END .................................C=100, epsilon=0.5; total time=   3.3s\n",
      "[CV] END ...................................C=100, epsilon=1; total time=   2.1s\n",
      "[CV] END ...................................C=100, epsilon=1; total time=   1.9s\n",
      "[CV] END ...................................C=100, epsilon=1; total time=   2.2s\n",
      "[CV] END ...................................C=100, epsilon=1; total time=   2.1s\n",
      "[CV] END ...................................C=100, epsilon=1; total time=   2.2s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# We will define a grid of hyperparameters as a dictionary. The keys are the hyperparameter names, and the values are lists of possible values to try.\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 5, 10, 20, 50, 100],\n",
    "    'epsilon': [0.001, 0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    svr, # the model\n",
    "    param_grid, # the grid of hyperparameters\n",
    "    verbose=2 # print the progress\n",
    ")\n",
    "\n",
    "svr = grid_search.fit(X_train_nosmiles, y_train) # GridSearchCV.fit() returns the best model, and we can save it to a new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebc8f7c1b8fb2afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'cv': None, 'error_score': nan, 'estimator__C': 1.0, 'estimator__cache_size': 200, 'estimator__coef0': 0.0, 'estimator__degree': 3, 'estimator__epsilon': 0.1, 'estimator__gamma': 'scale', 'estimator__kernel': 'rbf', 'estimator__max_iter': -1, 'estimator__shrinking': True, 'estimator__tol': 0.001, 'estimator__verbose': False, 'estimator': SVR(), 'n_jobs': None, 'param_grid': {'C': [1, 5, 10, 20, 50, 100], 'epsilon': [0.001, 0.01, 0.1, 0.5, 1]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 2}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- SMILES\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Report the best hyperparameters and RMSE on the testing set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, svr\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m----> 7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting set rmse:\u001b[39m\u001b[38;5;124m'\u001b[39m, mean_squared_error(y_test, y_pred))\n",
      "File \u001b[1;32mK:\\Gry\\anaconda\\envs\\pum24\\lib\\site-packages\\sklearn\\model_selection\\_search.py:499\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    498\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mK:\\Gry\\anaconda\\envs\\pum24\\lib\\site-packages\\sklearn\\svm\\_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 433\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mK:\\Gry\\anaconda\\envs\\pum24\\lib\\site-packages\\sklearn\\svm\\_base.py:613\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    610\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m--> 613\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[0;32m    623\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32mK:\\Gry\\anaconda\\envs\\pum24\\lib\\site-packages\\sklearn\\base.py:529\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    466\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    471\u001b[0m ):\n\u001b[0;32m    472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    533\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m         )\n",
      "File \u001b[1;32mK:\\Gry\\anaconda\\envs\\pum24\\lib\\site-packages\\sklearn\\base.py:462\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    458\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m     )\n\u001b[1;32m--> 462\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- SMILES\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Report the best hyperparameters and RMSE on the testing set\n",
    "\n",
    "print('Best hyperparameters:', svr.get_params())\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "print('-'*50)\n",
    "print('Testing set rmse:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84dd5deebbd0d9",
   "metadata": {},
   "source": [
    "### *Randomized search\n",
    "\n",
    "`RandomizedSearchCV` is an alternative to `GridSearchCV`. Instead of trying all possible combinations of fixed hyperparameters, it samples a fixed number of hyperparameter settings from specified probability distributions. Although you may be hesitant to use it, as it is not an exhaustive search, it is often more efficient than grid search. Randomized search is especially useful when we have many hyperparameters to tune, and we are not sure which ones are the most important. Take a look at the figure below and try to understand why this is the case.\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/grid-vs-random.png\", width=\"600\">\n",
    "</center>\n",
    "\n",
    "Randomized search is implemented in the same way as grid search, but with a different class. It also requires a dictionary of hyperparameters, but instead of specifying a list of values to try, we specify a **probability distribution**. See the example below:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_distributions = {\n",
    "    'some_discete_hyperparameter': np.arange(1, 10), # uniform dicrete distribution from 1 to 10\n",
    "    'some_continuous_hyperparameter': uniform(0, 1), # uniform continuous distribution from 0 to 1\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions,\n",
    "    n_iter=100, # number of random samples to try\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86bf1e4ca2c1d0",
   "metadata": {},
   "source": [
    "## Saving and loading Python objects\n",
    "\n",
    "Both the featurizer and the trained regression model can be saved to disk as Python objects using the `pickle` module. This way, we can load them later in another script without the need to retrain the model or recalculate the molecular descriptors.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "\n",
    "with open('path/to/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load the model\n",
    "\n",
    "with open('path/to/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb403d9e17203e7",
   "metadata": {},
   "source": [
    "---\n",
    "# Lab 4-2: Coding a simple app in Streamlit.\n",
    "\n",
    "Streamlit is a Python library that allows you to create very nice-looking and user-friendly web applications with just a few lines of code. It is very easy to use and requires absolutely no knowledge of HTML, CSS, or JavaScript.\n",
    "\n",
    "---\n",
    "\n",
    "We should have Streamlit already installed in our environment. You probably should take a look at the [Streamlit documentation](https://docs.streamlit.io/library), but this is how you can run a simple Streamlit app:\n",
    "\n",
    "Take look at `data/streamlit/app.py`. It is a tiny Streamlit app that takes a name as input and **returns a random fortune cookie-like quote**. Analyze the code and try to understand how it works. \n",
    "\n",
    "**Some important functions you may need to use:**\n",
    "\n",
    "- `st.title` sets the title of the app\n",
    "- `st.write` writes text to the app (supports [Markdown](https://www.markdownguide.org/basic-syntax/) synthax for text formatting)\n",
    "- `st.dataframe` displays a dataframe\n",
    "- `st.latex` renders LaTeX code (for mathematical formulas)\n",
    "- `st.text_input` creates a text input field (for multiline inputs, use `st.text_area`)\n",
    "- `st.button` creates a button (you can use it to trigger some action)\n",
    "\n",
    "To run the app, open a terminal and run the following command:\n",
    "\n",
    "    streamlit run data/streamlit/app.py\n",
    "    \n",
    "This will start a local server and open a new tab in your browser with the app. You can now interact with the app by entering your name and clicking the button to get a random fortune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89948b93e1fa0",
   "metadata": {},
   "source": [
    "## Exercise 5: Build an app for solubility prediction (3 points)\n",
    "\n",
    "This exercise is a continuation of the previous one. We will use all the code we have written so far to build a simple web app that predicts the solubility of molecules. The app will run in the browser and allow the user to input one or more SMILES strings, and it will display the predicted solubility of the molecules.\n",
    "The [Streamlit documentation](https://docs.streamlit.io/library) will be very helpful in this task.\n",
    "\n",
    "**The app should have the following structure:**\n",
    "\n",
    "1. A title and a short description of what the app does.\n",
    "2. A text area where the user can input a SMILES string (or multiple SMILES strings in a column).\n",
    "3. A button to submit the input.\n",
    "4. A section that displays the predicted solubility of the molecule(s) as a table of SMILES strings and their corresponding solubility values.\n",
    "\n",
    "The app should use our `Featurizer` class to extract the features from the input SMILES strings and predict the solubility using the trained model. **The model and the featurizer should not be trained inside the app, but loaded from a `.pkl` file instead!** Thanks to this approach, we will not need the training data to run the app. Both the model and the featurizer are already trained and saved as Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500173bbd37dfa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this exercise, you should create a new Python script called in the 'data/streamlit' directory and implement the app there.\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Featurizer:\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, train_smiles):\n",
    "        self.scaler = StandardScaler()\n",
    "        train_descriptors = self.get_descriptors(train_smiles)\n",
    "        self.scaler.fit(train_descriptors)\n",
    "\n",
    "    def featurize(self, smiles):\n",
    "        descriptors = self.get_descriptors(smiles)\n",
    "        scaled_descriptors = self.scaler.transform(descriptors)\n",
    "        return scaled_descriptors\n",
    "\n",
    "    def get_descriptors(self, smiles):\n",
    "        df = pd.DataFrame({'SMILES':smiles})\n",
    "        df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "        df['mol_wt'] = df['mol'].apply(rdMolDescriptors.CalcExactMolWt)             # Molecular weight\n",
    "        df['logp'] = df['mol'].apply(Crippen.MolLogP)                               # LogP (lipophilicity)\n",
    "        df['num_heavy_atoms'] = df['mol'].apply(rdMolDescriptors.CalcNumHeavyAtoms) # Number of heavy atoms\n",
    "        df['num_HBD'] = df['mol'].apply(rdMolDescriptors.CalcNumHBD)                # Number of hydrogen bond donors\n",
    "        df['num_HBA'] = df['mol'].apply(rdMolDescriptors.CalcNumHBA)                # Number of hydrogen bond acceptors\n",
    "        df['aromatic_rings'] = df['mol'].apply(rdMolDescriptors.CalcNumAromaticRings) # Number of aromatic rings\n",
    "        return  df[['mol_wt', 'num_heavy_atoms', 'num_HBD', 'num_HBA', 'aromatic_rings', 'logp']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae1047c-d0b0-4e90-b5b7-e03ed8ed7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db517bd4-77c9-49b8-82a1-1b2dbd505979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "#save svm\n",
    "\n",
    "with open('data/svr.pkl', 'wb') as f:\n",
    "    pkl.dump(svr, f)\n",
    "\n",
    "with open('data/svr.pkl', 'rb') as f:\n",
    "    svr_loaded = pkl.load(f)\n",
    "\n",
    "with open('data/featurizer.pkl', 'wb') as c:\n",
    "    pkl.dump(Featurizer, c)\n",
    "\n",
    "with open('data/featurizer.pkl', 'rb') as c:\n",
    "    featurizer_loaded = pkl.load(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef0ee928-872d-4138-84a3-62db58c06f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 19:45:50.011 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.573 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run K:\\Gry\\anaconda\\envs\\pum24\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-01-25 19:45:50.576 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.606 Session state does not function when running a script without `streamlit run`\n",
      "2025-01-25 19:45:50.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.612 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-25 19:45:50.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"data/featurizer.pkl\") as featurizer_class:\n",
    "    loaded_featurizer = pkl.load(featurizer_class)\n",
    "\n",
    "with open('data/svr.pkl', 'rb') as f:\n",
    "    svr_loaded = pkl.load(f)\n",
    "\n",
    "st.title('Solubility prediction machine')\n",
    "st.write(\"Hello! You have encountered a magic ball \\n\"\n",
    "             \"(Just imagine it's a version of the Magic 8-Ball)\"\n",
    "             \"that enables you to predict the solubility of chosen molecules based on their SMILES!\"\n",
    "             \"Input a SMILES string to check it's solubility, AND BE READY FOR MAGIC!\")\n",
    "              \n",
    "smiles = st.text_input(\"Input a SMILES string\")\n",
    "\n",
    "if st.button(\"**GENERATE**\", icon=\"\"):\n",
    "    guess = pd.DataFrame()\n",
    "    smiles = [st.session_state.SMILES]\n",
    "    guess['SMILES'] = smiles\n",
    "    prediction = featurizer.featurize(guess[\"SMILES\"])   # Extract features for the new dataset\n",
    "    y_pred = svr.predict(prediction)  # Use the SVR model to predict the solubility\n",
    "    guess['Solubility'] = y_pred  # Add the predictions to the dataframe\n",
    "    guess.head()\n",
    "\n",
    "    if not smiles:    # if the user did not enter a smiles string, display a warning message\n",
    "        st.write(':red[Enter SMILES to discover the full power of the machine]')\n",
    "        st.stop()   # stop the execution of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0acf87b-a2c7-47a4-84c0-7fcea58c55b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m guess \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc1ccccc1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m[\u001b[49m\u001b[43mguess\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "guess = [\"c1ccccc1\"]\n",
    "data = pd.DataFrame[guess]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab6cdc-8e8d-4fd1-a4a7-e2beab6d1dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
